{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Zags_Main_3.7fix.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZAGS4pnjbmI1"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/random-object/ai/blob/main/Zags_Main_3_7fix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAGS4j8u0gdN"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAGS4aH_BPGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff6e2ef-8a2d-4625-d2ba-4e7c0240ed31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtK7KvgqCI-k"
      },
      "source": [
        "# Stopped mid level = 2? use continue\n",
        "# Stopped mid level = 1 or 0? use upsample\n",
        "\n",
        "lemode = 'primed'     # 'ancestral','primed','continue','cutcontinue','upsample'\n",
        "lemodel = '5b_lyrics'                          #5b_lyrics or '5b' or '1b_lyrics'\n",
        "\n",
        "lecount = 3\n",
        "lesample_length_in_seconds = 90\n",
        "lesampling_temperature = .98\n",
        "lehop = [.75,1,.125]                 #default [.5,.5,.125], optimized [1,1,0.0625]\n",
        "\n",
        "lepath = '/content/gdrive/MyDrive/samplessongai'\n",
        "\n",
        "leprompt_length_in_seconds=12  \n",
        "leaudio_file = '/content/gdrive/MyDrive/magicshadow.wav'                    \n",
        "\n",
        "lecut = 70               # used only on cutcontinue\n",
        "transpose = [0,1,2]      # used only on cutcontinue [0,1,2] = default, ex [1,1,1] all samples are copied from item 1\n",
        "\n",
        "leexportlyrics = False\n",
        "leprogress = True\n",
        "leautorename = True\n",
        "\n",
        "leartist = \"burzum\"\n",
        "legenre = \"black\"\n",
        "lelyrics = \"\"\"When the Black clouds cover the moon\n",
        "And reality turns into nightmare\n",
        "Lighting cuts through the dark sky\n",
        "Almighty Perun gave us his sign !\n",
        "Brothers, wolves, I summon you !\n",
        "Wind will bring you my howling\n",
        "And smell of the human blood\n",
        "Yes, I found another sacrifice\n",
        "Droops of blood upon the stone\n",
        "I lick the cold virgins corpse\n",
        "I an blinded by my bloodlust\n",
        "I the Northern Carpathians\n",
        "Mystic eyes between the trees\n",
        "Brothers hungry for the blood\n",
        "Through the blood I find desire\n",
        "The only sense of the evil life\n",
        "Immortality is true\n",
        "For the creatures without shadows\n",
        "There is hell on the earth\n",
        "In the Northern Carpathians...\n",
        "Unholy woods of mysteries\n",
        "Alone witches full of hate\n",
        "Werewolves hidden in the caves\n",
        "Forgotten spells of pagan past\n",
        "Long nights and hours of darkness\n",
        "Cold mountain winds blow through the trees\n",
        "Diabolic feast around the fire\n",
        "Dark shadows dancing with flames\n",
        "There is a place where Evil lives\n",
        "There are woods where people die\n",
        "At midnight blood is more precious than gold\n",
        "In the Northern Carpathians...\n",
        "\"\"\"\n",
        "\n",
        "lechunk_size = 16 \n",
        "lemax_batch_size = lecount\n",
        "lelower_batch_size = lechunk_size\n",
        "lelower_level_chunk_size = lechunk_size * 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-8cvPn3CO4s"
      },
      "source": [
        "# 1 Sample\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAGS4k1WCC_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f168ea-247d-4c26-f055-dbe1eb225833"
      },
      "source": [
        "if lemode=='ancestral':\n",
        "  leprompt_length_in_seconds=None  \n",
        "  leaudio_file = None\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "codes_file=None\n",
        "\n",
        "!pip install git+https://github.com/openai/jukebox.git\n",
        "\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave start\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "filex = \"/usr/local/lib/python3.7/dist-packages/jukebox/sample.py\"\n",
        "fin = open(filex, \"rt\")\n",
        "data = fin.read()\n",
        "fin.close()\n",
        "\n",
        "newtext = '''import fire\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from termcolor import colored\n",
        "from datetime import datetime\n",
        "\n",
        "newtosample = True'''\n",
        "data = data.replace('import fire',newtext)\n",
        "\n",
        "newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n",
        "        counterr = 0\n",
        "        x = None\n",
        "        for start in starts:'''\n",
        "data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n",
        "\n",
        "newtext = '''global newtosample\n",
        "    newtosample = (new_tokens > 0)\n",
        "    if new_tokens <= 0:'''\n",
        "data = data.replace('if new_tokens <= 0:',newtext)\n",
        "\n",
        "newtext = '''counterr += 1\n",
        "            datea = datetime.now()\t\t\n",
        "            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n",
        "            if newtosample and counterr < len(starts):\n",
        "                del x; x = None; prior.cpu(); empty_cache()\n",
        "                x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
        "                logdir = f\"{hps.name}/level_{level}\"\n",
        "                if not os.path.exists(logdir):\n",
        "                    os.makedirs(logdir)\n",
        "                t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n",
        "                save_wav(logdir, x, hps.sr)\n",
        "                del x; prior.cuda(); empty_cache(); x = None\n",
        "            dateb = datetime.now()\n",
        "            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n",
        "            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ New to Sample: \" + str(newtosample) + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr > 1 and newtosample])'''\n",
        "data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n",
        "\n",
        "\n",
        "newtext = \"\"\"lepath=hps.name\n",
        "        if level==2:\n",
        "          for filex in glob(os.path.join(lepath + '/level_2','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-'))\n",
        "        if level==1:\n",
        "          for filex in glob(os.path.join(lepath + '/level_1','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L1-'))\n",
        "        if level==0:\n",
        "          for filex in glob(os.path.join(lepath + '/level_0','item_*.wav')):\n",
        "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L0-'))\n",
        "        save_html(\"\"\"\n",
        "if leautorename:\n",
        "  data = data.replace('save_html(',newtext)\n",
        "\n",
        "if leexportlyrics == False:\n",
        "  data = data.replace('if alignments is None','#if alignments is None')\n",
        "  data = data.replace('alignments = get_alignment','#alignments = get_alignment')\n",
        "  data = data.replace('save_html(','#save_html(')\n",
        "\n",
        "if leprogress == False:\n",
        "  data = data.replace('print(f\"Step \" +','#print(f\"Step \" +')\n",
        "  \n",
        "fin = open(filex, \"wt\")\n",
        "fin.write(data)\n",
        "fin.close()\n",
        "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave end\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "model = lemodel\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = lecount \n",
        "hps.name = lepath\n",
        "\n",
        "chunk_size = lechunk_size\n",
        "max_batch_size = lemax_batch_size\n",
        "\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = lehop\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = lemode\n",
        "codes_file=None\n",
        "audio_file = leaudio_file\n",
        "prompt_length_in_seconds=leprompt_length_in_seconds\n",
        "\n",
        "\n",
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [0, 1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = mode if 'continue' in mode else 'upsample'\n",
        "      codes_file = data\n",
        "      print(mode + 'ing from level ' + str(level))\n",
        "      break\n",
        "print('mode is now '+mode)\n",
        "\n",
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
        "\n",
        "sample_length_in_seconds = lesample_length_in_seconds \n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
        "\n",
        "metas = [dict(artist = leartist,\n",
        "            genre = legenre,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = lelyrics,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "\n",
        "#----------------------------------------------------------2\n",
        "\n",
        "\n",
        "sampling_temperature = lesampling_temperature\n",
        "lower_batch_size = lelower_batch_size\n",
        "max_batch_size = lemax_batch_size\n",
        "lower_level_chunk_size = lelower_level_chunk_size\n",
        "chunk_size = lechunk_size \n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
        "\n",
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  print(sample_hps.prompt_length_in_seconds)\n",
        "  print(hps.sr)\n",
        "  print(top_prior.raw_to_tokens)\n",
        "  print('aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.52')\n",
        "  print(duration)\n",
        "  print(audio_files)\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'continue':\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'cutcontinue':\n",
        "  print('-------CUT INIT--------')\n",
        "  lecutlen = (int(lecut*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  print(lecutlen)\n",
        "  data = t.load(codes_file, map_location='cpu')\n",
        "  zabaca = [z.cuda() for z in data['zs']]\n",
        "  print(zabaca)\n",
        "  assert zabaca[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  priorsz = [top_prior] * 3\n",
        "  top_raw_to_tokens = priorsz[-1].raw_to_tokens\n",
        "  assert lecutlen % top_raw_to_tokens == 0, f\"Cut-off duration {lecutlen} not an exact multiple of top_raw_to_tokens\"\n",
        "  assert lecutlen//top_raw_to_tokens <= zabaca[-1].shape[1], f\"Cut-off tokens {lecutlen//priorsz[-1].raw_to_tokens} longer than tokens {zs[-1].shape[1]} in saved codes\"\n",
        "  zabaca = [z[:,:lecutlen//prior.raw_to_tokens] for z, prior in zip(zabaca, priorsz)]\n",
        "  hps.sample_length = lecutlen\n",
        "  print(zabaca)\n",
        "  zs = _sample(zabaca, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  del data\n",
        "  print('-------CUT OK--------')\n",
        "  hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zibica = [z.cuda() for z in data['zs']]\n",
        "  zubu = zibica[:]\n",
        "  if transpose != [0,1,2]:\n",
        "    zubu[2][0] = zibica[:][2][transpose[0]];zubu[2][1] = zibica[:][2][transpose[1]];zubu[2][2] = zibica[:][2][transpose[2]]\n",
        "    zubu[1][0] = zibica[:][1][transpose[0]];zubu[1][1] = zibica[:][1][transpose[1]];zubu[1][2] = zibica[:][1][transpose[2]]\n",
        "    zubu[0][0] = zibica[:][0][transpose[0]];zubu[0][1] = zibica[:][0][transpose[1]];zubu[0][2] = zibica[:][0][transpose[2]]\n",
        "  zubu = _sample(zubu, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "  print('-------CONTINUE AFTER CUT OK--------')\n",
        "  zs = zubu\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
        "\n",
        "\n",
        "\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/jukebox.git\n",
            "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-yr7tajjq\n",
            "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-yr7tajjq\n",
            "Collecting fire==0.1.3\n",
            "  Downloading fire-0.1.3.tar.gz (33 kB)\n",
            "Collecting tqdm==4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from jukebox==1.0) (0.10.3.post1)\n",
            "Collecting unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting numba==0.48.0\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 51.3 MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 14.0 MB/s \n",
            "\u001b[?25hCollecting mpi4py>=3.0.0\n",
            "  Downloading mpi4py-3.1.1.tar.gz (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 48.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 104 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48.0->jukebox==1.0) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.20)\n",
            "Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=197917 sha256=786b49b03213719e17343503724e6af2ff3d9374f8064db881e143b1d727bb1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_49nffbz/wheels/d6/42/39/91f8a32505a445499702ae0f887769e6bb5030c42382d74ae0\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49719 sha256=70a4d537fe39b72834ffaa4a09695f8c85cfc3aff29d3ba3e4430511a8643b3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/c5/df/d9bf8223023d31343b65f1cc57d2dc005610ebbcd2b4a5d1e7\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612900 sha256=c24739bb91a53e58c32e6c9f42a693a9f0f3221398a9352c10aff47c3a789763\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/9e/42/3224f85730f92fa2925f0b4fb6ef7f9c5431a64dfc77b95b39\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.1-cp37-cp37m-linux_x86_64.whl size=2180606 sha256=3aaa32bba8fbba21da055d2b6bdf687f749f9173dfc4c3a74eeea4d5a6a72d29\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/be/c0/2b0347be1de5cd8ca9fe67da7ec8c3fe8930fcb6b0df6f2255\n",
            "Successfully built jukebox fire librosa mpi4py\n",
            "Installing collected packages: llvmlite, numba, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.1 numba-0.48.0 tqdm-4.45.0 unidecode-1.1.1\n",
            "Using cuda True\n",
            "22:28:10\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
            "0: Converting to fp16 params\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "mode is now primed\n",
            "12\n",
            "44100\n",
            "128\n",
            "aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.52\n",
            "529152\n",
            "['/content/gdrive/MyDrive/magicshadow.wav']\n",
            "Sampling level 2\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 4134 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "259/259 [00:54<00:00,  4.76it/s]\n",
            "4058/4058 [08:24<00:00,  8.04it/s]\n",
            "Step \u001b[34m1\u001b[0m/\u001b[31m24\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[33m???\u001b[0m\n",
            "Sampling 8192 tokens for [1024,9216]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:50<00:00,  4.07it/s]\n",
            "1024/1024 [02:14<00:00,  7.60it/s]\n",
            "Step \u001b[34m2\u001b[0m/\u001b[31m24\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m92.21864813333333\u001b[0m\n",
            "Sampling 8192 tokens for [2048,10240]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "117/448 [00:21<01:06,  4.95it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGS4pnjbmI1"
      },
      "source": [
        "# 2 Upsample\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAGS4LolpZ6w"
      },
      "source": [
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "del top_prior\n",
        "empty_cache()\n",
        "top_prior=None\n",
        "\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
        "\n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
        "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}